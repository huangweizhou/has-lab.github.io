---
layout: post
title: DeACT Architecture-Aware Virtual Memory Support for Fabric Attached Memory Systems
author: Weizhou Huang
tags:
 - HPCA
 - 2021
 - Heterogeneous meomry system
 - Virtual memory
 - Address translation
---

# [DeACT: Architecture-Aware Virtual Memory Support for Fabric Attached Memory Systems](https://arxiv.org/pdf/2008.00171)

本文针对异构内存系统提出了低开销的透明访问控制和地址转换机制,无需修改内核和应用。

## 背景和问题：

最近工业界热门的内存架构（称为memory-centric architectures）是将内存模块与计算节点分离，使计算节点可以访问多个内存节点，从而增加计算节点的物理内存容量，以满足现代应用对内存的需求。这样的例子比如，Facebook的分布式Rack，HPE实验室的*The Machine*,因特尔的Rack Sack。 
这种架构的优势在于高性能、灵活、低成本。

另一方面，实现内存语义协议并可以轻松与系统集成的内存模块被称为Fabric-Attached Memories（FAM）。FAM为HPC中的计算节点提供了通过快速互联访问共享物理内存池的能力。
在HPC系统中，将FAM应用到memory-centric architectures的内存节点可以使计算节点通过快速互联和已定义好的协议访问大容量的FAM池（包含多个相互独立FAM节点）。

在上述的memory-centric architecture架构中，如图1（b）所示，有两种方式实现对FAM节点的访问控制。一种方法是通过一个memory broker节点将所有FAM节点的的物理内存抽象成一片连续的内存空间（I-FAM），类似于虚拟机的二维地址转换，计算节点访问由memory broker节点提供的抽象后的地址，然后通过memory broker转换成FAM节点的物理地址。在I-FAM架构下，在与计算节点直接相连的路由器中可以植入一个STU（system translation unit），用于缓存计算节点的地址到FAM地址的映射信息，以及下发地址转换服务请求或向memory broker请求分配一个物理页。
如图1（a）所示，第二种方式是直接将计算节点暴露给FAM节点的物理地址，计算节点修改内核，通过与memory broker通信以分配物理内存页（E-FAM）。这种方式能够提供较高的性能，但是无法实现访问控制。

**问题在于**，目前没有一种能在memory-centric architecture架构下，同时保证FAM的安全性（访问控制）并降低FAM内存地址转换开销的机制。
表1对比较了两种方式的优缺点，I-FAM的优点在于无需修改计算节点内核比你高且提供了对FAM节点的访问控制，但是如图2（b）所示，-FAM的缺点在于二维地址转换的性能开销很高，因为一旦TLB未命中，就需要去内存查询24次才能获取一个4KB物理页的FAM地址，远远高于一维页表查询（图2（a））的次数和延时。E-FAM。E-FAM的优点在于消除了I-FAM的二维地址转换，因此性能较高，但是无法提供访问控制，并且需要修改计算节点的内核，复杂度与安全性都无法满足需求。










<center>

<img src="../images/DeACT-框架图.png" width="65%" height="65%" />

图 1  两种FAM架构
</center>

<center>

<img src="../images/DeACT-PTW.png" width="65%" height="65%" />

图 2  （a）本地内存一维页表查询（b）虚拟化场景下二维页表查询

</center>


<center>

<img src="../images/DeACT-表1.png" width="65%" height="65%" />

表 1  FAM架构对比
</center>

## 设计：
**设计思想：**
根据上述观察，本文基于I-FAM架构，将访问控制和地址转换解耦，在计算节点内的本地内存中缓存未经检验的地址转换信息，同时在系统级别（STU单元）执行访问控制和页表查询。

根据设计思想，下面简述设计实现：

1. *访问控制* ：
   
安全性由STU检查某个计算节点对FAM内存地址的访问控制实现的。
访问控制信息记录在FAM的特定区域（称为ACM）中，ACM的地址事先注册在STU中，因此只要访问ACM对应的地址就能查询到某个FAM数据页的访问控制信息。
图3描述了访问控制的元数据布局。访问控制信息由node ID（14bit）， read、write、modify权限（2bit）组成。入股哦某个FAM内存被多个计算节点共享，那么这个FAM内存的node ID为14位全1。然而，还需要额外的元数据记录一个共享的FAM内存能被哪些计算节点访问，因此每1GB的FAM内存用8KB的位图记录有哪些计算节点可以访问这一段内存。

当STU检查访问权限时，会先去ACM中检查node ID，如果为全1，则立即插叙对应的位图，检查当前节点是否具有访问这段共享FAM内存的权限；如果访问的不是共享内存，则只需比较node ID是否匹配。


<center>

<img src="../images/DeACT-ACM.png" width="65%" height="65%" />

图 3  内存页访问控制元数据和位图

</center>


2. *加速地址转换* ：

本文提出将计算节点地址到FAM内存地址的映射信息缓存在计算节点本地内存，以加速二维地址转换。

具体实现：如图4①②所示，本文分别在计算节点的内存控制器中实现了FAM translator和FAM translation cache（类似于现有MMU内部的TLB），每次在进行FAM内存访问时，FAM translator会先去查询FAM translation cache，如果命中，意味着获取到FAM内存地址，接着执行图4中第③步，即STU读取ACM以检查访问权限；如果cache未命中，FAM translator会请求STU进行FAM内存页表访问（图4④），并更新FAM translation cache（图4⑤）。





<center>

<img src="../images/DeACT-地址转换.png" width="65%" height="65%" />

图 4  DeACT地址转换流程

</center>


## 实验：
用[Structural Simulation Toolkit (SST)](http://sst-simulator.org/)仿真DeACT，
用[Opal](https://www.semanticscholar.org/paper/Opal%3A-A-Centralized-Memory-Manager-for-Memory-Kommareddy-Hughes/1447cc5b2f8cb33a76bc54bc9572e419eefe46ad) 分布式内存模型和内存管理器模拟FAM架构。





